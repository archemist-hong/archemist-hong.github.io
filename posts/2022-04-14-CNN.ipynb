{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33a15389",
   "metadata": {},
   "source": [
    "# Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25fae9",
   "metadata": {},
   "source": [
    "CNN은 크게 Feature Extractor와 Classifier, 2가지 부분으로 구분된다.\n",
    "\n",
    "Input으로 부터 Feature를 추출하는 역할은 Convolution, Pooling Layer로 수행하며,\n",
    "\n",
    "추출된 Feature를 Flatten 하여, Dense Layer를 사용한 Classifier가 Input을 분류하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cd8fd",
   "metadata": {},
   "source": [
    "## Lenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde38581",
   "metadata": {},
   "source": [
    "예를 들어, 다음과 같은 구조를 갖는 CNN 모델을 생각할 수 있다.\n",
    "\n",
    "X => Conv2D => AvgPooling2D => Conv2D => AvgPooling2D => Conv2D => Flatten (여기까지 Feature Extractor) => Dense => Dense => Softmax (Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d010318",
   "metadata": {},
   "source": [
    "## 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4623686c",
   "metadata": {},
   "source": [
    "### Shapes in the Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25372b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : (32, 3, 28, 28)\n",
      "W/B : (5, 3, 3, 3)/(5,)\n",
      "After conv1 : (32, 5, 28, 28)\n",
      "After conv pool1 : (32, 5, 14, 14)\n",
      "W/B : (5, 5, 3, 3)/(5,)\n",
      "After conv2 : (32, 5, 14, 14)\n",
      "After conv pool2 : (32, 5, 7, 7)\n",
      "After flatten : (32, 245)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N, I_c, I_h, I_w = 32, 3, 28, 28\n",
    "n_conv_filter = 5\n",
    "kernel_size = 3\n",
    "pool_size, pool_strides = 2, 2\n",
    "batch_size = 32\n",
    "\n",
    "x = torch.randn(N, I_c, I_h, I_w)\n",
    "\n",
    "conv1 = torch.nn.Conv2d(I_c, n_conv_filter, kernel_size = kernel_size, padding = 1)\n",
    "relu = torch.nn.ReLU()\n",
    "conv1_pool = torch.nn.MaxPool2d(kernel_size = pool_size, stride = pool_strides)\n",
    "\n",
    "conv2 = torch.nn.Conv2d(n_conv_filter, n_conv_filter, kernel_size = kernel_size, padding = 1)\n",
    "conv2_pool = torch.nn.MaxPool2d(kernel_size = pool_size, stride = pool_strides)\n",
    "\n",
    "flatten = torch.nn.Flatten()\n",
    "\n",
    "print(f\"Input : {x.detach().numpy().shape}\")\n",
    "\n",
    "x = conv1(x)\n",
    "x = relu(x)\n",
    "W, B = conv1.weight, conv1.bias\n",
    "print(f\"W/B : {W.detach().numpy().shape}/{B.detach().numpy().shape}\")\n",
    "print(f\"After conv1 : {x.detach().numpy().shape}\")\n",
    "x = conv1_pool(x)\n",
    "print(f\"After conv pool1 : {x.detach().numpy().shape}\")\n",
    "\n",
    "x = conv2(x)\n",
    "x = relu(x)\n",
    "W, B = conv2.weight, conv2.bias\n",
    "print(f\"W/B : {W.detach().numpy().shape}/{B.detach().numpy().shape}\")\n",
    "print(f\"After conv2 : {x.detach().numpy().shape}\")\n",
    "x = conv2_pool(x)\n",
    "print(f\"After conv pool2 : {x.detach().numpy().shape}\")\n",
    "\n",
    "x = flatten(x)\n",
    "print(f\"After flatten : {x.detach().numpy().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313bf71e",
   "metadata": {},
   "source": [
    "### Shapes in the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d46ddef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature : (32, 245)\n",
      "W/B : (50, 245)/(50,)\n",
      "After dense1 : (32, 50)\n",
      "W/B : (25, 50)/(25,)\n",
      "After dense2 : (32, 25)\n",
      "W/B : (10, 25)/(10,)\n",
      "After dense3 : (32, 10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "n_neurons = [50, 25, 10]\n",
    "\n",
    "dense1 = torch.nn.Linear(245, n_neurons[0])\n",
    "dense2 = torch.nn.Linear(n_neurons[0], n_neurons[1])\n",
    "dense3 = torch.nn.Linear(n_neurons[1], n_neurons[2])\n",
    "relu = torch.nn.ReLU()\n",
    "softmax = torch.nn.Softmax(dim = 1)\n",
    "\n",
    "print(f\"Input feature : {x.detach().numpy().shape}\")\n",
    "\n",
    "x = dense1(x)\n",
    "x = relu(x)\n",
    "W, B = dense1.weight, dense1.bias\n",
    "print(f\"W/B : {W.detach().numpy().shape}/{B.detach().numpy().shape}\")\n",
    "print(f\"After dense1 : {x.detach().numpy().shape}\")\n",
    "\n",
    "x = dense2(x)\n",
    "x = relu(x)\n",
    "W, B = dense2.weight, dense2.bias\n",
    "print(f\"W/B : {W.detach().numpy().shape}/{B.detach().numpy().shape}\")\n",
    "print(f\"After dense2 : {x.detach().numpy().shape}\")\n",
    "\n",
    "x = dense3(x)\n",
    "x = softmax(x)\n",
    "W, B = dense3.weight, dense3.bias\n",
    "print(f\"W/B : {W.detach().numpy().shape}/{B.detach().numpy().shape}\")\n",
    "print(f\"After dense3 : {x.detach().numpy().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3fc28",
   "metadata": {},
   "source": [
    "### Implementation with Sequential Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1923bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "N, I_c, I_h, I_w = 4, 3, 28, 28\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "kernel_size = 3\n",
    "padding = 1\n",
    "pool_size, pool_strides = 2, 2\n",
    "\n",
    "x = torch.randn(N, I_c, I_h, I_w)\n",
    "\n",
    "model = torch.nn.Sequential()\n",
    "model.add_module('conv1', torch.nn.Conv2d(I_c, n_conv_neurons[0], kernel_size = kernel_size, padding = padding))\n",
    "model.add_module('relu1', torch.nn.ReLU())\n",
    "model.add_module('MaxPool1', torch.nn.MaxPool2d(kernel_size = pool_size, stride = pool_strides))\n",
    "model.add_module('flatten', torch.nn.Flatten())\n",
    "\n",
    "model.add_module('dense1', torch.nn.Linear(1960, n_dense_neurons[0]))\n",
    "model.add_module('relu2', torch.nn.ReLU())\n",
    "model.add_module('dense2', torch.nn.Linear(n_dense_neurons[0], n_dense_neurons[1]))\n",
    "model.add_module('relu3', torch.nn.ReLU())\n",
    "model.add_module('dense3', torch.nn.Linear(n_dense_neurons[1], n_dense_neurons[2]))\n",
    "model.add_module('softmax', torch.nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531aa67e",
   "metadata": {},
   "source": [
    "### Implementation with Model Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "433774c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TestCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(I_c, n_conv_neurons[0], kernel_size = kernel_size, padding = padding)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size = pool_size, stride = pool_strides)\n",
    "        self.conv2 = torch.nn.Conv2d(n_conv_neurons[0], n_conv_neurons[1], kernel_size = kernel_size, padding = padding)\n",
    "        self.conv3 = torch.nn.Conv2d(n_conv_neurons[1], n_conv_neurons[2], kernel_size = kernel_size, padding = padding)\n",
    "\n",
    "        \n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        self.dense1 = torch.nn.Linear(270, n_dense_neurons[0])\n",
    "        self.dense2 = torch.nn.Linear(n_dense_neurons[0], n_dense_neurons[1])\n",
    "        self.dense3 = torch.nn.Linear(n_dense_neurons[1], n_dense_neurons[2])\n",
    "        \n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "N, I_c, I_h, I_w = 4, 3, 28, 28\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "kernel_size = 3\n",
    "padding = 1\n",
    "pool_size, pool_strides = 2, 2\n",
    "\n",
    "x = torch.randn(N, I_c, I_h, I_w)\n",
    "model = TestCNN()\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5c476",
   "metadata": {},
   "source": [
    "### Implementation with Sequential + layer sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f16dd964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MyConv(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(MyConv, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channel, out_channel, kernel_size = kernel_size, padding = padding)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size = pool_size, stride = pool_strides)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "    \n",
    "model = torch.nn.Sequential()\n",
    "model.add_module('conv1', MyConv(I_c, n_conv_neurons[0]))\n",
    "model.add_module('conv2', MyConv(n_conv_neurons[0], n_conv_neurons[1]))\n",
    "model.add_module('conv3', MyConv(n_conv_neurons[1], n_conv_neurons[2]))\n",
    "model.add_module('flatten', torch.nn.Flatten())\n",
    "\n",
    "model.add_module('dense1', torch.nn.Linear(270, n_dense_neurons[0]))\n",
    "model.add_module('relu2', torch.nn.ReLU())\n",
    "model.add_module('dense2', torch.nn.Linear(n_dense_neurons[0], n_dense_neurons[1]))\n",
    "model.add_module('relu3', torch.nn.ReLU())\n",
    "model.add_module('dense3', torch.nn.Linear(n_dense_neurons[1], n_dense_neurons[2]))\n",
    "model.add_module('softmax', torch.nn.Softmax(dim = 1))\n",
    "\n",
    "x = torch.randn(N, I_c, I_h, I_w)\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6756c8",
   "metadata": {},
   "source": [
    "### Implementation with Model and Layer-Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "192453ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MyConv(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(MyConv, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channel, out_channel, kernel_size = kernel_size, padding = padding)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size = pool_size, stride = pool_strides)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "    \n",
    "class TestCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = MyConv(I_c, n_conv_neurons[0])\n",
    "        self.conv2 = MyConv(n_conv_neurons[0], n_conv_neurons[1])\n",
    "        self.conv3 = MyConv(n_conv_neurons[1], n_conv_neurons[2])\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        self.dense1 = torch.nn.Linear(270, n_dense_neurons[0])\n",
    "        self.dense2 = torch.nn.Linear(n_dense_neurons[0], n_dense_neurons[1])\n",
    "        self.dense3 = torch.nn.Linear(n_dense_neurons[1], n_dense_neurons[2])\n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "x = torch.randn(N, I_c, I_h, I_w)\n",
    "model = TestCNN()\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01cf2b3",
   "metadata": {},
   "source": [
    "### LeNet with Model Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2f71444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "        self.avgpool = torch.nn.AvgPool2d(kernel_size = 2)\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, kernel_size = 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, kernel_size = 5)\n",
    "        self.conv3 = torch.nn.Conv2d(16, 120, kernel_size = 5)\n",
    "        \n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        self.dense1 = torch.nn.Linear(120, 84)\n",
    "        self.dense2 = torch.nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"x: {}\".format(x. shape))\n",
    "        x = self.conv1(x)\n",
    "        x = self.tanh(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.avgpool(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.conv2(x)\n",
    "        x = self.tanh(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.avgpool(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.conv3(x)\n",
    "        x = self.tanh(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self. flatten(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.dense1(x) \n",
    "        x = self.tanh(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.dense2(x)\n",
    "        x = self.softmax(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        return x\n",
    "    \n",
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36c029",
   "metadata": {},
   "source": [
    "### LeNet with Hybrid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75485551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ConvLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, pool):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.ispool = pool\n",
    "        self.conv = torch.nn.Conv2d(in_channel, out_channel, kernel_size = 5)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        if pool:\n",
    "            self.pool = torch.nn.AvgPool2d(kernel_size = 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.tanh(x)\n",
    "        if self.ispool:\n",
    "            x = self.pool(x)\n",
    "        return x\n",
    "    \n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = ConvLayer(1, 6, True)\n",
    "        self.conv2 = ConvLayer(6, 16, True)\n",
    "        self.conv3 = ConvLayer(16, 120, False)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.dense1 = torch.nn.Linear(120, 84)\n",
    "        self.dense2 = torch.nn.Linear(84, 10)\n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "model = LeNet()\n",
    "\n",
    "x = torch.randn(32, 1, 32, 32)\n",
    "predictions = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b8a1d",
   "metadata": {},
   "source": [
    "### Forward Propagation of LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de64bae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3007827\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class ConvLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, pool):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.ispool = pool\n",
    "        self.conv = torch.nn.Conv2d(in_channel, out_channel, kernel_size = 5)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        if pool:\n",
    "            self.pool = torch.nn.AvgPool2d(kernel_size = 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.tanh(x)\n",
    "        if self.ispool:\n",
    "            x = self.pool(x)\n",
    "        return x\n",
    "    \n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = ConvLayer(1, 6, True)\n",
    "        self.conv2 = ConvLayer(6, 16, True)\n",
    "        self.conv3 = ConvLayer(16, 120, False)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.dense1 = torch.nn.Linear(120, 84)\n",
    "        self.dense2 = torch.nn.Linear(84, 10)\n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "### Dataset Preparation ###\n",
    "transforms = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                 transforms.ToTensor()])\n",
    "dataset = datasets.MNIST(root='mnist_data', \n",
    "                               train=True, \n",
    "                               transform=transforms,\n",
    "                               download=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                         batch_size=32, \n",
    "                                         shuffle=True)\n",
    "\n",
    "### Foward Propagation ###\n",
    "model = LeNet()\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "for images, labels in dataloader:\n",
    "    predictions = model(images)\n",
    "    loss = loss_function(predictions, labels)\n",
    "    print(loss.detach().numpy())\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
